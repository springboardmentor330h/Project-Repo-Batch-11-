{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1-9djA-3Eiv4VSyJ5DhU2RaJI8ympRqfP","authorship_tag":"ABX9TyNeKPseAbaEzoy+Y6c105zI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**DEPENDENCIES**"],"metadata":{"id":"YhxR5Ko6cem9"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"LMU6oKRscWVb","executionInfo":{"status":"ok","timestamp":1771409751461,"user_tz":-330,"elapsed":18028,"user":{"displayName":"Manasi N","userId":"07680321668724852566"}},"outputId":"95a4c290-312f-4db2-b93e-52a95d3b1e5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting streamlit>=1.38.0 (from -r /content/drive/MyDrive/podcast-project/requirements.txt (line 2))\n","  Downloading streamlit-1.54.0-py3-none-any.whl.metadata (9.8 kB)\n","Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/podcast-project/requirements.txt (line 3)) (2.2.2)\n","Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/podcast-project/requirements.txt (line 4)) (2.0.2)\n","Requirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/podcast-project/requirements.txt (line 5)) (4.67.3)\n","Collecting faster-whisper>=1.0.0 (from -r /content/drive/MyDrive/podcast-project/requirements.txt (line 8))\n","  Downloading faster_whisper-1.2.1-py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/podcast-project/requirements.txt (line 9)) (2.9.0+cpu)\n","Requirement already satisfied: torchaudio>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/podcast-project/requirements.txt (line 10)) (2.9.0+cpu)\n","Requirement already satisfied: sentence-transformers>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/podcast-project/requirements.txt (line 13)) (5.2.2)\n","Collecting vaderSentiment>=3.3.2 (from -r /content/drive/MyDrive/podcast-project/requirements.txt (line 16))\n","  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n","Requirement already satisfied: plotly>=5.15.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/podcast-project/requirements.txt (line 19)) (5.24.1)\n","Requirement already satisfied: wordcloud>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/podcast-project/requirements.txt (line 20)) (1.9.6)\n","Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/podcast-project/requirements.txt (line 21)) (3.10.0)\n","Requirement already satisfied: nltk>=3.8.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/podcast-project/requirements.txt (line 24)) (3.9.1)\n","Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/podcast-project/requirements.txt (line 25)) (1.6.1)\n","Collecting mutagen>=1.47.0 (from -r /content/drive/MyDrive/podcast-project/requirements.txt (line 28))\n","  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: pydub>=0.25.1 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/podcast-project/requirements.txt (line 31)) (0.25.1)\n","Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/podcast-project/requirements.txt (line 34)) (2.9.0.post0)\n","Collecting unidecode>=1.3.8 (from -r /content/drive/MyDrive/podcast-project/requirements.txt (line 35))\n","  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (1.9.0)\n","Collecting cachetools<7,>=5.5 (from streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2))\n","  Downloading cachetools-6.2.6-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (8.3.1)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (3.1.46)\n","Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (26.0)\n","Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (11.3.0)\n","Collecting pydeck<1,>=0.8.0b4 (from streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2))\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (5.29.6)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (2.32.4)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (9.1.4)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (0.10.2)\n","Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (6.5.1)\n","Requirement already satisfied: typing-extensions<5,>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (4.15.0)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (6.0.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 3)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 3)) (2025.3)\n","Collecting ctranslate2<5,>=4.0 (from faster-whisper>=1.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 8))\n","  Downloading ctranslate2-4.7.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n","Requirement already satisfied: huggingface-hub>=0.21 in /usr/local/lib/python3.12/dist-packages (from faster-whisper>=1.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 8)) (1.4.1)\n","Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper>=1.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 8)) (0.22.2)\n","Collecting onnxruntime<2,>=1.14 (from faster-whisper>=1.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 8))\n","  Downloading onnxruntime-1.24.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n","Collecting av>=11 (from faster-whisper>=1.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 8))\n","  Downloading av-16.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 9)) (3.21.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 9)) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 9)) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 9)) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 9)) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 9)) (2025.3.0)\n","Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=3.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 13)) (5.0.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=3.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 13)) (1.16.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 21)) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 21)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 21)) (4.61.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 21)) (1.4.9)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 21)) (3.3.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.8.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 24)) (1.5.3)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.8.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 24)) (2025.11.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 25)) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 34)) (1.17.0)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (4.26.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (2.16.0)\n","Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.12/dist-packages (from ctranslate2<5,>=4.0->faster-whisper>=1.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 8)) (6.0.3)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (4.0.12)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper>=1.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 8)) (1.2.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper>=1.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 8)) (0.28.1)\n","Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper>=1.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 8)) (1.5.4)\n","Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21->faster-whisper>=1.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 8)) (0.23.0)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime<2,>=1.14->faster-whisper>=1.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 8)) (25.12.19)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 9)) (3.0.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (2026.1.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 9)) (1.3.0)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers>=3.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 13)) (0.7.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (5.0.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.21->faster-whisper>=1.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 8)) (4.12.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.21->faster-whisper>=1.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 8)) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.21->faster-whisper>=1.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 8)) (0.16.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (25.4.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (2025.9.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (0.37.0)\n","Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit>=1.38.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 2)) (0.30.0)\n","Requirement already satisfied: typer>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.21->faster-whisper>=1.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 8)) (0.23.0)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.23.0->typer-slim->huggingface-hub>=0.21->faster-whisper>=1.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 8)) (13.9.4)\n","Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.23.0->typer-slim->huggingface-hub>=0.21->faster-whisper>=1.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 8)) (0.0.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer>=0.23.0->typer-slim->huggingface-hub>=0.21->faster-whisper>=1.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 8)) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer>=0.23.0->typer-slim->huggingface-hub>=0.21->faster-whisper>=1.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 8)) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.23.0->typer-slim->huggingface-hub>=0.21->faster-whisper>=1.0.0->-r /content/drive/MyDrive/podcast-project/requirements.txt (line 8)) (0.1.2)\n","Downloading streamlit-1.54.0-py3-none-any.whl (9.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading faster_whisper-1.2.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading av-16.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (41.2 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cachetools-6.2.6-py3-none-any.whl (11 kB)\n","Downloading ctranslate2-4.7.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (39.0 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.0/39.0 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.24.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: unidecode, mutagen, ctranslate2, cachetools, av, vaderSentiment, pydeck, onnxruntime, streamlit, faster-whisper\n","  Attempting uninstall: cachetools\n","    Found existing installation: cachetools 7.0.1\n","    Uninstalling cachetools-7.0.1:\n","      Successfully uninstalled cachetools-7.0.1\n","Successfully installed av-16.1.0 cachetools-6.2.6 ctranslate2-4.7.1 faster-whisper-1.2.1 mutagen-1.47.0 onnxruntime-1.24.1 pydeck-0.9.1 streamlit-1.54.0 unidecode-1.4.0 vaderSentiment-3.3.2\n"]}],"source":["# Install required packages\n","!pip install -r /content/drive/MyDrive/podcast-project/requirements.txt"]},{"cell_type":"code","source":["# Install localtunnel (no auth token needed)\n","!npm install -g localtunnel"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bq3PbWF5ccba","executionInfo":{"status":"ok","timestamp":1771409757249,"user_tz":-330,"elapsed":4680,"user":{"displayName":"Manasi N","userId":"07680321668724852566"}},"outputId":"02dca7c3-4358-44c1-e598-3bd5ef851381"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K\n","added 22 packages in 4s\n","\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K\n","\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K3 packages are looking for funding\n","\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K  run `npm fund` for details\n","\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0K"]}]},{"cell_type":"markdown","source":["**UTILS**"],"metadata":{"id":"48cDcwWgcgP5"}},{"cell_type":"code","source":["# app/utils.py\n","%%writefile /content/drive/MyDrive/podcast-project/data/app/utils.py\n","\n","import streamlit as st\n","import os\n","import re\n","import json\n","from io import BytesIO\n","from pathlib import Path\n","import base64\n","\n","import pandas as pd\n","import numpy as np\n","import torch\n","\n","# AUDIO PROCESSING IMPORTS\n","from pydub import AudioSegment\n","from mutagen.easyid3 import EasyID3\n","from mutagen.id3 import ID3\n","from mutagen.mp3 import MP3\n","import unidecode\n","\n","\n","# NLP / MODEL IMPORTS\n","import nltk\n","from nltk.tokenize import sent_tokenize\n","from nltk.corpus import stopwords\n","from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","from sentence_transformers import SentenceTransformer, util\n","from faster_whisper import WhisperModel\n","\n","# VISUALIZATION\n","from wordcloud import WordCloud\n","import plotly.graph_objects as go\n","\n","# DOWNLOAD NLTK DATA\n","nltk.download(\"punkt\", quiet=True)\n","nltk.download(\"punkt_tab\", quiet=True)\n","nltk.download(\"stopwords\", quiet=True)\n","\n","# ============================================================\n","# GLOBAL MODELS\n","# ============================================================\n","\n","@st.cache_resource\n","def load_whisper_model():\n","    \"\"\"\n","    Loads Whisper speech-to-text model.\n","    Uses GPU if available, otherwise CPU.\n","    Cached to prevent reloading on every rerun.\n","    \"\"\"\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    return WhisperModel(\"tiny\", device=device)\n","\n","@st.cache_resource\n","def load_embedder():\n","    \"\"\"\n","    Loads Sentence-BERT model for embeddings.\n","    Used for segmentation, summarization, and keyword ranking.\n","    \"\"\"\n","    return SentenceTransformer(\"all-MiniLM-L6-v2\")\n","\n","@st.cache_resource\n","def load_sentiment_analyzer():\n","    \"\"\"\n","    Loads VADER sentiment analyzer.\n","    \"\"\"\n","    return SentimentIntensityAnalyzer()\n","\n","# Instantiate global models once\n","WHISPER_MODEL = load_whisper_model()\n","EMBEDDER = load_embedder()\n","SENTIMENT_ANALYZER = load_sentiment_analyzer()\n","\n","# ============================================================\n","# GLOBAL SIDEBAR\n","# ============================================================\n","\n","def render_global_sidebar(logo_path: Path):\n","    \"\"\"\n","    Renders shared sidebar across all pages.\n","    Includes: Logo, Dark mode toggle\n","    \"\"\"\n","    with st.sidebar:\n","\n","        if logo_path.exists():\n","            st.image(logo_path, width=180)\n","        else:\n","            st.markdown(\"## ğŸ™ï¸ Castly\")\n","\n","        if \"dark_mode\" not in st.session_state:\n","            st.session_state.dark_mode = False\n","\n","        st.session_state.dark_mode = st.toggle(\n","            \"Dark Mode\",\n","            value=st.session_state.dark_mode,\n","            key=\"global_dark_toggle\"\n","        )\n","\n","        st.divider()\n","\n","    return st.session_state.dark_mode\n","\n","# ============================================================\n","# APPLY THEME\n","# ============================================================\n","\n","def apply_theme(dark_mode: bool):\n","\n","    if dark_mode:\n","        bg = \"#0f172a\"\n","        text = \"#e2e8f0\"\n","        card = \"#1e293b\"\n","        sidebar_bg = \"#111827\"\n","        border = \"#334155\"\n","        muted = \"#94a3b8\"       # Secondary text\n","    else:\n","        bg = \"#f9fafb\"\n","        text = \"#1e293b\"\n","        card = \"white\"\n","        sidebar_bg = \"#ffffff\"\n","        border = \"#e5e7eb\"\n","        muted = \"#6b7280\"\n","\n","    # Custom CSS\n","    st.markdown(f\"\"\"\n","    <style>\n","\n","    /* Main app */\n","    [data-testid=\"stAppViewContainer\"] {{\n","        background-color: {bg};\n","        color: {text};\n","    }}\n","\n","    /* Sidebar */\n","    section[data-testid=\"stSidebar\"] {{\n","        background-color: {sidebar_bg} !important;\n","        border-right: 1px solid {border};\n","    }}\n","\n","    /* Cards */\n","    .card {{\n","        background: {card};\n","        border-radius: 14px;\n","        padding: 1.5rem;\n","        border: 1px solid {border};\n","        box-shadow: 0 6px 20px rgba(0,0,0,0.15);\n","        margin-bottom: 1.5rem;\n","    }}\n","\n","    /* Feature cards */\n","    .feature-card {{\n","        height: 220px;\n","        display: flex;\n","        flex-direction: column;\n","        justify-content: space-between;\n","    }}\n","\n","    /* Headings */\n","    h1, h2, h3, h4 {{\n","        color: {text} !important;\n","    }}\n","\n","    /* Muted text */\n","    p {{\n","        color: {muted};\n","    }}\n","\n","    /* Buttons */\n","    .stButton > button {{\n","        border-radius: 10px;\n","        border: 1px solid {border};\n","    }}\n","\n","    /* Inputs */\n","    .stTextInput input,\n","    .stSelectbox div[data-baseweb=\"select\"] {{\n","        background-color: {card} !important;\n","        color: {text} !important;\n","    }}\n","\n","    /* Expanders */\n","    div[data-testid=\"stExpander\"] {{\n","        background-color: {card};\n","        border: 1px solid {border};\n","        border-radius: 12px;\n","    }}\n","\n","    /* Divider */\n","    hr {{\n","        border-color: {border};\n","    }}\n","\n","    footer {{\n","        visibility: hidden;\n","    }}\n","\n","    </style>\n","    \"\"\", unsafe_allow_html=True)\n","\n","# ============================================================\n","# AUDIO HELPERS\n","# ============================================================\n","\n","def get_audio_title(audio_bytes: BytesIO, filename: str) -> str:\n","    \"\"\"\n","    Extracts title metadata from MP3.\n","    Falls back to filename if metadata unavailable.\n","    \"\"\"\n","    title = Path(filename).stem.replace(\"_\", \" \").title()\n","    try:\n","        tmp = \"temp_title.mp3\"\n","        audio_bytes.seek(0)\n","        with open(tmp, \"wb\") as f:\n","            f.write(audio_bytes.read())\n","\n","        audio = MP3(tmp)\n","        tags = EasyID3(tmp)\n","        title = tags.get(\"title\", [title])[0]\n","\n","        os.remove(tmp)\n","    except:\n","        pass\n","\n","    return title\n","\n","# AUDIO TRIMMING\n","def trim_audio_if_needed(audio_bytes, quick_demo):\n","    \"\"\"\n","    If quick demo mode enabled,\n","    trims audio to first 10 minutes.\n","    \"\"\"\n","\n","    if not quick_demo:\n","        return audio_bytes\n","\n","    st.info(\"Trimming to first 10 minutes...\")\n","\n","    audio_bytes.seek(0)  # Reset pointer before processing\n","\n","    input_size = len(audio_bytes.getvalue())\n","\n","    try:\n","        audio = AudioSegment.from_file(audio_bytes)\n","        audio = audio[:10 * 60 * 1000]  # Slice first 10 minutes\n","        trimmed = BytesIO()\n","        audio.export(trimmed, format=\"wav\")\n","        trimmed.seek(0)\n","        trimmed_size = len(trimmed.getvalue())\n","        st.write(f\"Trimmed size: {trimmed_size} bytes\")\n","        return trimmed\n","    except Exception as e:\n","        st.error(f\"Trim failed: {e}\")\n","        audio_bytes.seek(0)\n","        return audio_bytes\n","\n","def extract_cover_art(audio_bytes: BytesIO, filename: str) -> str:\n","    \"\"\"\n","    Extracts embedded album art (APIC frame).\n","    Returns base64 image string if available.\n","    \"\"\"\n","    try:\n","        tmp = \"temp_cover.mp3\"\n","        audio_bytes.seek(0)\n","        with open(tmp, \"wb\") as f:\n","            f.write(audio_bytes.read())\n","\n","        tags = ID3(tmp)\n","        for tag in tags.values():\n","            if tag.FrameID == \"APIC\":\n","                mime = tag.mime\n","                data = tag.data\n","                base64_img = base64.b64encode(data).decode(\"utf-8\")\n","                os.remove(tmp)\n","                return f\"data:{mime};base64,{base64_img}\"\n","\n","        os.remove(tmp)\n","    except:\n","        pass\n","\n","    return None\n","\n","@st.cache_data\n","def extract_segment_clip(audio_bytes: BytesIO, start_sec: float, duration_sec: int = 90):\n","    \"\"\"\n","    Extracts short audio clip for preview playback.\n","    Default duration: 90 seconds.\n","    \"\"\"\n","    audio_bytes.seek(0)\n","    try:\n","        audio = AudioSegment.from_file(audio_bytes)\n","        start_ms = int(start_sec * 1000)\n","        end_ms = min(start_ms + duration_sec * 1000, len(audio))\n","\n","        clip = audio[start_ms:end_ms]\n","        buffer = BytesIO()\n","        clip.export(buffer, format=\"mp3\")\n","        buffer.seek(0)\n","        return buffer\n","    except:\n","        return BytesIO()\n","\n","# ============================================================\n","# TRANSCRIPTION\n","# ============================================================\n","\n","def transcribe_audio(audio_bytes: BytesIO):\n","    \"\"\"\n","    Runs Whisper transcription.\n","    Adds language detection + romanization.\n","    \"\"\"\n","\n","    tmp = \"temp_upload.wav\"\n","    audio_bytes.seek(0)\n","\n","    with open(tmp, \"wb\") as f:\n","        f.write(audio_bytes.read())\n","\n","    segments, info = WHISPER_MODEL.transcribe(tmp)\n","    os.remove(tmp)\n","\n","    detected_lang = info.language.lower()\n","\n","    # Store detected language globally\n","    st.session_state.detected_language = detected_lang\n","\n","    sentences = []\n","\n","    for seg in segments:\n","        text = seg.text.strip()\n","        sents = sent_tokenize(text)\n","\n","        duration = (seg.end - seg.start) / max(len(sents), 1)\n","        current_time = seg.start\n","\n","        for s in sents:\n","\n","            romanized = (\n","                unidecode.unidecode(s)\n","                if detected_lang != \"en\"\n","                else s\n","            )\n","\n","            sentences.append({\n","                \"text\": s,\n","                \"romanized\": romanized,\n","                \"language\": detected_lang,\n","                \"start\": current_time,\n","                \"end\": current_time + duration\n","            })\n","\n","            current_time += duration\n","\n","    return sentences\n","\n","# ============================================================\n","# SEGMENTATION\n","# ============================================================\n","\n","def create_segments(sentences, threshold=0.65, min_segment_size=3):\n","    \"\"\"\n","    Groups sentences into topic-based segments.\n","    Uses cosine similarity between embeddings.\n","    \"\"\"\n","    if not sentences:\n","        return []\n","\n","    texts = [s[\"text\"] for s in sentences]\n","    embeddings = EMBEDDER.encode(texts, convert_to_tensor=True)\n","\n","    segments = []\n","    current_segment = [sentences[0]]\n","    current_embeddings = [embeddings[0]]\n","\n","    for i in range(1, len(sentences)):\n","\n","        segment_mean = torch.mean(torch.stack(current_embeddings), dim=0)\n","        similarity = util.cos_sim(segment_mean, embeddings[i])[0][0].item()\n","\n","        if similarity < threshold and len(current_segment) >= min_segment_size:\n","            segments.append(current_segment)\n","            current_segment = [sentences[i]]\n","            current_embeddings = [embeddings[i]]\n","        else:\n","            current_segment.append(sentences[i])\n","            current_embeddings.append(embeddings[i])\n","\n","    if current_segment:\n","        segments.append(current_segment)\n","\n","    return segments\n","\n","# ============================================================\n","# ENRICHMENT\n","# ============================================================\n","\n","def generate_summary(text: str, max_sentences=3):\n","    \"\"\"\n","    Extractive summarization using embedding similarity\n","    between sentence vectors and document centroid.\n","    \"\"\"\n","    sentences = sent_tokenize(text)\n","\n","    if len(sentences) <= max_sentences:\n","        return text\n","\n","    sentence_embeddings = EMBEDDER.encode(sentences, convert_to_tensor=True)\n","    document_embedding = torch.mean(sentence_embeddings, dim=0)\n","\n","    scores = util.cos_sim(document_embedding, sentence_embeddings)[0]\n","    ranked = sorted(zip(sentences, scores.tolist()), key=lambda x: x[1], reverse=True)\n","\n","    top_sentences = [s for s, _ in ranked[:max_sentences]]\n","\n","    # Preserve original order\n","    final_summary = [s for s in sentences if s in top_sentences]\n","\n","    return \" \".join(final_summary)\n","\n","def get_keywords(text: str, top_n=6):\n","    \"\"\"\n","    Extracts top semantic keywords.\n","    Ranks candidate words via embedding similarity.\n","    \"\"\"\n","    words = re.findall(r\"\\b[a-zA-Z]{3,}\\b\", text.lower())\n","    stop = set(stopwords.words(\"english\"))\n","    candidates = list(set([w for w in words if w not in stop]))\n","\n","    if not candidates:\n","        return []\n","\n","    segment_embedding = EMBEDDER.encode(text, convert_to_tensor=True)\n","    word_embeddings = EMBEDDER.encode(candidates, convert_to_tensor=True)\n","\n","    scores = util.cos_sim(segment_embedding, word_embeddings)[0]\n","    ranked = sorted(zip(candidates, scores.tolist()), key=lambda x: x[1], reverse=True)\n","\n","    return [w for w, _ in ranked[:top_n]]\n","\n","def highlight_keywords(text: str, keywords: list):\n","    \"\"\"\n","    Wraps keywords in HTML span for UI highlighting.\n","    \"\"\"\n","    if not keywords:\n","        return text\n","\n","    for kw in keywords:\n","        text = re.sub(\n","            rf\"\\b({re.escape(kw)})\\b\",\n","            r\"<span class='kw'>\\1</span>\",\n","            text,\n","            flags=re.IGNORECASE\n","        )\n","    return text\n","\n","# ============================================================\n","# LIBRARY HELPERS\n","# ============================================================\n","\n","def load_library_data(segment_dir: Path) -> pd.DataFrame:\n","    \"\"\"\n","    Loads all episode JSON files and returns\n","    a flattened DataFrame (one row per segment).\n","    Computes sentiment dynamically.\n","    \"\"\"\n","    rows = []\n","\n","    if not segment_dir.exists():\n","        return pd.DataFrame()\n","\n","    for f in segment_dir.glob(\"*.json\"):\n","        try:\n","            data = json.load(open(f, encoding=\"utf-8\"))\n","            ep_match = re.search(r\"\\d+\", data.get(\"episode_id\", \"\"))\n","            ep_num = int(ep_match.group()) if ep_match else 0\n","\n","            for seg in data.get(\"segments\", []):\n","                text = seg.get(\"text_preview\", \"\")\n","                score = SENTIMENT_ANALYZER.polarity_scores(text)[\"compound\"]\n","\n","                sentiment = (\n","                    \"Positive\" if score >= 0.05 else\n","                    \"Negative\" if score <= -0.05 else\n","                    \"Neutral\"\n","                )\n","\n","                start = seg.get(\"start_time_sec\", 0.0)\n","                duration = seg.get(\"duration_sec\", 60)\n","\n","                rows.append({\n","                    \"episode\": ep_num,\n","                    \"segment\": seg.get(\"segment_id\", 0),\n","                    \"summary\": seg.get(\"summary\", \"\"),\n","                    \"keywords\": seg.get(\"keywords\", []),\n","                    \"text\": text,\n","                    \"start_sec\": start,\n","                    \"end_sec\": start + duration,\n","                    \"sentiment\": sentiment,\n","                    \"sentiment_score\": round(score, 2)\n","                })\n","\n","        except:\n","            pass\n","\n","    return pd.DataFrame(rows)\n","\n","def load_episode_titles(csv_path: Path):\n","    \"\"\"Returns episode_number â†’ title mapping.\"\"\"\n","    try:\n","        df_titles = pd.read_csv(csv_path)\n","        df_titles[\"episode_number\"] = df_titles[\"episode_number\"].astype(str)\n","        return dict(zip(df_titles[\"episode_number\"], df_titles[\"title\"]))\n","    except:\n","        return {}\n","\n","def get_episode_image_path(image_dir: Path, episode: int):\n","    \"\"\"Returns episode cover image path if available.\"\"\"\n","    for ext in [\".jpg\", \".jpeg\", \".png\", \".JPG\", \".PNG\"]:\n","        img = image_dir / f\"{episode}{ext}\"\n","        if img.exists():\n","            return img\n","    return None\n","\n","def get_audio_path(audio_dir: Path, episode: int):\n","    \"\"\"Returns episode audio file path if available.\"\"\"\n","    for ext in [\".mp3\", \".m4a\", \".wav\"]:\n","        path = audio_dir / f\"{episode}{ext}\"\n","        if path.exists():\n","            return path\n","    return None\n","\n","# ============================================================\n","# TIMELINE HELPER\n","# ============================================================\n","\n","def create_timeline_plot(df: pd.DataFrame):\n","    \"\"\"\n","    Creates horizontal bar timeline of segments.\n","    Sentiment determines color.\n","    \"\"\"\n","    fig = go.Figure()\n","\n","    colors = {\n","        \"Positive\": \"#10b981\",\n","        \"Negative\": \"#ef4444\",\n","        \"Neutral\": \"#f59e0b\"\n","    }\n","\n","    for _, r in df.iterrows():\n","        duration = (r[\"end_sec\"] - r[\"start_sec\"]) / 60\n","\n","        fig.add_trace(go.Bar(\n","            x=[duration],\n","            y=[\"Timeline\"],\n","            base=[r[\"start_sec\"] / 60],\n","            orientation=\"h\",\n","            marker_color=colors.get(r[\"sentiment\"], \"#94a3b8\"),\n","            showlegend=False\n","        ))\n","\n","    fig.update_layout(\n","        height=160,\n","        xaxis_title=\"Time (minutes)\",\n","        yaxis_visible=False\n","    )\n","\n","    return fig"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uKFVVIgscjk7","executionInfo":{"status":"ok","timestamp":1771409764160,"user_tz":-330,"elapsed":16,"user":{"displayName":"Manasi N","userId":"07680321668724852566"}},"outputId":"8a3c7d42-1e25-47c7-89ac-5f15104ffead"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/drive/MyDrive/podcast-project/data/app/utils.py\n"]}]},{"cell_type":"markdown","source":["**STOP ACTIVE APP PROCESSES**"],"metadata":{"id":"9JcQ-w0TvgBf"}},{"cell_type":"code","source":["!pkill -f streamlit   # Stop any running Streamlit processes\n","!pkill -f lt          # Stop any running LocalTunnel (lt) processes"],"metadata":{"id":"94GsAiP9dT7G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**STREAMLIT APP**"],"metadata":{"id":"bXmQS7k_vrLO"}},{"cell_type":"code","source":["# Start the Streamlit app in the background\n","# Expose the Streamlit app to the internet using LocalTunnel with specified subdomain\n","# Display the LocalTunnel access password (required to open the link)\n","\n","!streamlit run /content/drive/MyDrive/podcast-project/data/app/utils.py \\\n","& npx localtunnel --port 8501 --subdomain castly-utils \\\n","& wget -q -O - https://loca.lt/mytunnelpassword\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ef-_RbjbdWmw","executionInfo":{"status":"ok","timestamp":1771409784436,"user_tz":-330,"elapsed":10771,"user":{"displayName":"Manasi N","userId":"07680321668724852566"}},"outputId":"6de4b784-3987-4e6f-ccd3-2e3206314467"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["34.26.109.237\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n","\u001b[0m\n","\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kyour url is: https://castly-utils.loca.lt\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.26.109.237:8501\u001b[0m\n","\u001b[0m\n","\u001b[34m  Stopping...\u001b[0m\n"]}]}]}