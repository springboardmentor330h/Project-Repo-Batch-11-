
Segment 1 Summary:
Each models are no positional embedding, so they have in the dataset out to 512k context 

Segment 2 Summary:
Represented in the samples, they're validated out to 128k 

Segment 3 Summary:
The IBM team says, theoretically, you should be able to push it past that 

Segment 4 Summary:
So some really great long context performance 

Segment 5 Summary:
I think one of the key measurement points in the release notes are if you take 8 
