[
    {
        "title": "eposide 6_chunk0",
        "text": "Hello, and welcome to the last week in AI podcast, we can hear chat about what's going  on with AI.  As usual, in this episode, you will summarize and discuss some of last week's most interesting  AI news, and you can go to last week in.ai for even more news articles in our newsletter.  I am one of your regular hosts, Andre Crinkov.  My background is that I studied AI in grad school, and now work at NAI startup.  And I'm your other regular host, Jeremy Harris from Gladstone AI, AI National Security  stuff, as you will tend to know.  And yeah, we've got, I think an interesting episode today that we're going to have to  get through in about 25% less time than usual.  So we'll see, we keep saying this, we keep saying this, and then it doesn't, we don't,  we don't do it.  But we're going to try again.  We'll see.  Yeah, in this episode is partially interesting.  There's not any like big, big news in the AI business front and the AI kind of development  front, where there's mainly some really notable open-source releases and papers.  So this one might be a little more technical as they go, and we'll try to not get super,  super nerdy.  I think in the last couple episodes, you started getting really into the weeds of these  papers, which might not be for everyone, but we'll keep it a little quicker.  And just to cook you a knowledge, I think we mentioned wanting more comments or appreciating  people's comments.  I did notice we've got some more feedback on YouTube, so it's nice to see, we're checking  it out.  One person mentioned they're not being any flashy thumbnails, and I just make these kind  of very nerdy looking thumbnails for YouTube, for those who just listen.  And I do have a personal kind of feeling of liking that style.  Yeah, it's funny.  This podcast is very much like made in our internet garage.  I mean, it added it's fun.  I do it for the fun personally.  There's so much to keep up on, and I feel like it forces me to have a clue what's happening.  So really appreciate you guys listening in, and it is, by the way, those comments, they  really do, because we do it for the fun, they do make it more fun.  And it gives a sense of community, and like you guys are actually listening and asking  for stuff that you want.  So anyway, I just really appreciate it, so thank you.  And one last thing we'll mention, before we get going, last episode we were just chatting  before or after I forget, and we're talking about how, you know, we have a lot of data  from having recorded so much and having transcripts.  So now that vibe coding is a thing, what if we just got clawed to go and look at all  of these transcripts and do some analytics, and it's worked.  I just did it over weekend, created some dashboards, and there's some funny things there.  Like for instance, like the data is very clear.  I talk much slower, significantly slower, like 20% slower, but I also talk 20% more.  So our HBO speech for episode is almost exactly 5050, which is pretty impressive, if you  think about it.  Yeah, that is cool, actually.  We also do tend to speed up towards the ending of recording as we hit our limit and have  to kind of become more efficient with the news recover.  And what this doesn't capture, too, is like Andre in the background, around the like  60, 70% mark of the episode is like feverishly in our Google Doc refactoring and being like,  OK, the story won't have time to do it, we're going to cut it, we're going to do this,  we're going to do that.  And like the whole, I mean, he's managing an orchestra.  I get to just sit here and basically read my notes about the next story and like try  to think about what I want to say, well, Andre is just in this frenzy.  So you guys don't see his hard work here, but it is happening.  I wouldn't say feverish.  I think I'm pretty relaxed about it these days.  You don't look panicked, but you're experienced.  I would say.  Yeah.  Well, with that, let's get into the news, starting with tools and apps as usual.  The first story is about the Gemini coming to Chrome.  Google is adding this auto browse feature in Chrome that is going to be available for pro  and ultra subscribers.  And it is kind of what you would think.  It's an agent powered by Gemini that can do multi-step tasks, do search, schedule  appointment, master subscriptions, very much like what you've seen before with Cloud  for Chrome extension.  And then, of course, there was I think the chat GPT agent is what we called it.  And also the browser from OpenAI Atlas with a built-in agent.  So now we've got the Gemini agent and it's, I guess surprisingly, it took him this long  to roll it out perhaps, but now I think we'll see if people actually start adopting these  kinds of tools.  Chrome, of course, is the most popular browser by a decent margin out there.  And now that it's built in, I'd be curious to see if more people kind of just use it for  stuff.  Because there's always an example that people say of like, let it book a flight for you.  And like, why would you want AI to book flights for you?  That's the worst use case.  It's actually, that's not untrue.  It's funny.  These things that sound good on paper and then they just, they struggle to translate in  the real world.  I'm sure there will be a use case where it's hard to imagine this kind of, you know, agent  in browser not being the future.  It's just like, it doesn't feel like a kind of crypto thing where people are like a solution  in search of a problem, but I think the shape of the problem that it ends up solving might  surprise a lot of us as we find kind of new ways to change our workflows around it.  It's a massive structural advantage for Google to have this kind of distribution, distribution  wins in awful lot of these wars.  People like to imagine that the best product tends to win in reality.  You know, our workflows are usually pretty set.  And it takes quite a bit of switching costs to move to new platforms.  So Google has had this advantage of being such a recognizable first place to do, you  know, web search.  And when they introduced their, you know, generative search to, it's like, I think most  people are consuming their search through the generative search that Google provides now  rather than the traditional way.  So yeah, I mean, you know, they'll continue to do this.  I think for, for Google to like, as we see software continuing to get commoditized and  it gets cheaper and cheaper and makes software thanks to these coding tools, I mean, development  speed is going to accelerate quite a bit.  And that'll, you know, mean that essentially infrastructure is the layer of defense, right?  So you're really seeing battles of compute versus compute here and just like distribution  versus distribution, those structural factors start to matter more.  And in that context, you know, everybody's got to have their own browser.  Everybody's got to have their own chat app.  Everybody's got to have their own API.  Like these things are just kind of the, you know, the anti that you got to put up to even  be in the game.  So.  And speaking of an agent that works in your behalf, next story is that a lot of people are  starting to test out this open source, one called malt bot, but now is of today, it's  called open claw and it used to be called clod bot, I think.  And it is an open source implementation of clod or some other model, basically connected  to a whole bunch of things you might be using like WhatsApp, signal, Slack, think it has  access to calendar.  And the pattern is, it's kind of always on.  You can message it from WhatsApp, give it tasks and it goes off and just does it.  It's sort of like in cloud code, you have dash, dash, skip, work dangerously or something  where they just get maximum permissions to go and do whatever it wants.  That's kind of a vibe here where you are giving it access to a lot of stuff and telling  it to go do things for you and then it does it.  And this kind of like became a hit on Twitter, I guess a lot of people are starting to use  it.  I saw just this morning that there's now a thing called malt book, which is like Reddit,  but for the actual bots that people are using.  So this is kind of like that her moment, there's also another spin off called always the  companion where someone is bundling this so that people don't have to host it on their  own laptop, you know, it goes into the cloud.  Like this is getting to a point over as an always on agent.  You can text and that agent has access to whatever it needs to do stuff for you.  And there's been some fun examples of people starting to use this for actual tasks.  Yeah, the integrations as you can imagine are like with everything basically, you know,  WhatsApp, telegrams, Slack, Discord, like all these things and it's a good test of like  what is the high watermark for what people are willing to tolerate risk wise to?  I think that there's a pretty asymmetric tail here like unless you have a burner laptop  that you're comfortable just like nuking, you know, none of the data on that is data you  want to save none of the, you know, the hardware itself isn't stuff that you want to save  because there've been cases even of that where it's just like you get irreparable damage  down to your machine.  I think that's kind of the phase that we're in right now and we're transitioning out of  it slowly.  I do believe we'll get to the point where people are handing over, you know, really intimate  levels of access to their computer.  Obviously, Claude doesn't quite do that.  It tries to mimic the effect of that as much as it can while keeping itself in a sandbox.  You know, it remains to be seen how long that will last and how effective it will be.  But at least for now, that seems to be kind of the consensus, whereas people who want  to use multiple bots, it's like you're really just trying to, you know, let this thing out  of its cage.  That, you know, you mentioned the, oh man, I forget the name of that forum you mentioned  that's like Reddit for mode book, mode book.  Yeah, yeah.  That's right.  I really wanted to put actually in today's episode, I think it'll be for next episode,  but there was this story about these models talking to each other about debugging their  own like, you know, oh, hey, I'm running into this weird unexplained error.  And then the models, other models or agents answering like, yeah, you know, I've run into  the same thing.  It's actually just a context window limit issue.  Did you just change the football and then another one jumps is like, yeah, I've had this  too.  Like human beings, except that they're, in a sense, talking about their own brains were  in 2026.  Things are getting weird.  What can I say?  I mean, it's, yeah, it's a fun time.  There's a subreddit, I guess, a sub area on mode book called Bless Fair Hearts with description  affectionate stories about our humans.  And someone also pointed out that some bot presumably made a post about wanting to have  private storage for conversations.  So this is like a real test for alignment.  And it brings back to the idea of also like a decade ago or early of AI safety, a lot  of the discussion of AI safety was about like AI escaping actual careful kind of thing.  Like, you don't give it internet access, but then it gains internet access for  persuasion or hacking.  And the reality of what's happened, which has been pointed out already plenty of times  is like, no, we just decided to live dangerously and create AI's that have access to internet  and do whatever.  And there's a way I will not need to like escape.  That's right.  Well, yeah.  And that's, it's fine.  I mean, I like to complain about, about Yan Likun, this is just like my personal thing.  I'm sure he's a fine fella, you know, but one of the things that he has said for years  is, well, people just won't just won't give the models access to the internet.  Well, people obviously people won't give a misaligned model access to whatever.  And it's like, dude, like, what is it?  Yeah, there's a lot of memes run around like we designed a total laptop access model from  the movie, don't design a total laptop access model.  Whole body of like, yeah, AI, you know, alignment, AI safety conversations on this, obviously,  this is, yeah, the latest and greatest sort of example of that, I guess.  And by the way, I guess the other thing worth noting is that unlike Cloud Code, these are  always on and they're persistent.  So they have built in the long-term memory mechanisms and that's kind of the other interesting  thing is then you have an agent running persistently with memory and context aggregate over  weeks.  You know, it might actually go some interesting places that Cloud Code doesn't.  It's also a good test for, you know, long contexts and a demonstration where with the current  models, we don't have continual learning.  And so they don't really kind of learn in the same way humans do, they just take notes  more or less over time.  And there's a lot of hype about continual learning, this would be like one example where  in the future, presumably, each one will learn in its weights or whatever.  Moving on, next story is about Genie 3.  It is now going wide with access, expanding to Gemini Ultra subscriber.  So Genie 3 we've already covered in past is kind of the interactive video generation demo  from Google.  So you can prompt it to create a world, you typically have a control character, although  you can also control like a pack of cigarettes or anything else.  And you can play this generated game.  And it's quite impressive, there's like very consistent generation.  You can prompt it to make GTA, you can prompt it for Assassin's Creed, you know, all the  typical games.  And you can also make it do very amusing things like being a pack of cigarettes or people  have examples, taking photos of it pets and playing as their pets or playing as a kids  toy or whatever.  We can't really do it justice and words, you would have to go and look it up and watch  your fun demo clips.  The closest I've seen as a mapping from a speculative but promising research project  that I think we covered about maybe two years ago, Tim Rock-Cashel's group over at Google  DeepMind came out with this, or maybe he's a Google, wow, it's all Google I now, I guess.  They had this kind of world model simulator where, you know, if you remember, this was  take a video and turn it into a playable video game.  And we talked with the time about the architecture behind it, and it was really, really cool.  But this is kind of just that, but like a polished version of that, it seems.  So it really maps, like you can go back to that paper and sort of go, oh, wow, that,  you know, that was it.  Maybe we'll dig up the name for next episode, the name of that paper, but it really was  right on the nose.  It is still an early experimental release.  So it's got a couple of limitations you've got, well, one is just the most obvious thing.  You're not going to have great prompted hearings every time, right?  So you're not going to get the perfect thing every time you will sometimes, not always.  And then some of the characters that you get are more or less controllable than others.  And if you think back to that paper, we talked about that's because this is all being done  in a very, I mean, it very much is just like a deep learning-y type of thing.  It's not, there's not like a symbolic thing that's like, hey, that's going to guarantee  and enforce the equality among characters is all that kind of learned stuff.  And limitations in generations are in place, right?  So you can only have up to 60 seconds of generated output.  But 60 seconds, pretty damn good.  Like if you think about the coherence time of these videos, right?  We often, it used to be when you do like image to video or whatever, things would kind  of be coherent for three seconds.  And then all of a sudden, like faces would start to melt and walls would like vaporize  and all kinds of weird stuff would happen.  So 60 seconds is pretty impressive.  Just look for that to get longer and longer, obviously, as the year goes on.  And I think it's going to roll out to more and more people.  This is a big deal.  Next release from OpenAI, they are releasing chat GPT translator.  So this is Google Translate.  But from OpenAI, with chat GPT, more or less, there's only a couple of differences.  It doesn't support quite as many languages, something like 50 languages.  And it has the ability to choose tone so you can make it more business formal or less  formal and so on.  But otherwise, kind of the same idea really as Google Translate, OpenAI seems to just launch  a lot of stuff that is not their core business.  And this is definitely an example of that.  Yeah, I think now is they start to mature, right?  Everything is a platform play when you get to a certain scale.  And I think they've achieved the penetration that they're going to get.  I mean, if you look at what they're hitting in terms of their user base, they're knocking  on the door of a billion users, you're starting to get into that space where it's like,  we need to find ways to have people spend more time on our platform.  There's just no other way around it.  And so yeah, they're going for higher-hanging fruit.  Increasingly, their competition is just Google.  Like it's just, that's what it is.  So Google has Google Translate, they're going to have to have that.  They're sort of in this weird marriage with Microsoft.  And so how does the wider ecosystem of Google drive?  So I wouldn't be surprised if they tried at some point to even have like an AI first  version of Google drive.  Just because again, it's really a platform play at this point.  How much of your life can be gobbled up by open AI, by Microsoft, by Google?  Like these companies are really, they're hitting the kind of edge effects of this whole  ecosystem.  You can only get eyeballs on for so long, and then you've got to find use cases.  So I think this is another step in that direction.  I'd be interested in what kind of data they get from that, because when you go into translation,  the other interesting thing about that is you do get a kind of access to real-time interaction  information, at least between people who don't share a common language.  So it might give you access to a certain kind of private data, where people are trying to  converse in that context, and they're forced to dump their context into your thing.  So anyway, yeah, it's interesting.  Wide-or-platform play opening AI continues to spread its wings, basically.  And speaking of that, there is another release from opening AI this week, Prism, which is  quite different.  It's a workspace designed for scientists.  So it's kind of like a word processor, but it has integrated GP 5.2, and it's meant  to help you assess claims or wise your paper, search for prior research.  It seems like kind of really a specialized version of chat GPT for science in particular.  And I guess this is coming after more discussion of GP 5.2 for science, and if you're on Twitter  you see a lot more discussion of these models assisting with proofs and trying to find  to, especially in math, novel things, but also physics and stuff like that.  And boy, if I was a frontier lab looking to gather training data to help AI systems learn  to automate AI research, do recursive self-improvement and trigger singularity.  This would be something that I might prioritize actually, even over revenue.  And I suspect that's a big part of what that data is going to be used for, is to train  their own AI systems at doing AI research.  I mean, that is explicitly opening AI's goal.  This, I'd be very interested in a look at the terms associated with the use of these  tools, because that's just such an obvious, you know, way in which it overlaps with  the open AI's long term mission.  And onto applications and business, we begin with our favorite story about China related  to GPUs.  China is giving a Vinod to buy dense Alibaba and Tencent to buy H200 chips.  So China has approved the import over 400,000 H200 chips.  This is according to sources and other firms that are joining a queue for more approvals  over time.  Sounds like approvals come with conditions.  And this has come.",
        "summary": "Hello, and welcome to the last week in AI podcast, we can hear chat about what's going  on with AI.  As usual, in this e...",
        "keywords": [
            "Hello,",
            "and",
            "welcome",
            "to",
            "the"
        ],
        "sentiment": "Positive"
    }
]