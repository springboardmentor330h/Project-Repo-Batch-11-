[
    {
        "title": "eposide 7_chunk0",
        "text": "My main measure of productivity that I learned very early on was  my goal is to make the machines work for me as much as possible  and keep the GPUs full.  My goal during the day is to make a plan.  I guess you might call it a strategy,  although I didn't think of it as doing strategy, right?  And maybe that's the shift we all kind of need to make.  Hi, I'm Brian McCann.  I'm the CTO and co-founder at U.com.  I was an AI researcher in a past life  and a philosopher before that one.  So I'm super stoked to talk to Jeremy Hender today about AI,  where we're going, and everything it means for our teams,  our organizations, and ourselves as people.  I was one of the early U.com user.  I had the plug-in and introduced you to this whole kind of like  that basically search didn't have to be,  I searched something, but it could be a bespoke created answer to me,  which was kind of like need.  I would imagine a U obviously spoken many places  about this different, this is change that's coming to search.  If you are to offer people advice on how to think about  what's the best way for now attaining the information that they need.  And normally there would be a way you search better in Google,  obviously, increasingly we know that it's like more of a conversation,  but you probably thought a great deal about how do you click  as most efficient, get the best out of this information  now rendered through these agents?  What kind of your advice on how to become better at that?  Well, it's a skill right now.  Just like many of us had to learn at some point how to use Google.  And that was a form of searching for information.  People weren't really used to and it's still true that,  depending on how you phrase your query,  you're going to get different types of information  and you can encode all sorts of different biases into that.  But with prompts and how detailed you can be with prompts  and how important it is to get some of those details right,  given that agents now will run for minutes  or perhaps even hours in some cases.  So if you can describe accurately the problem that you're after,  I think that's a good and useful skill,  but I really hope that the need for that skill goes away very quickly  as well.  Most of what I tried to do on the deep research side of you.com  and the automated research side is expanding your queries,  rewriting your queries, discovering the unknown unknowns,  iterating on searches over time so that you don't have to.  My real hope is to move away from search to chat,  prompting, and then move away from that entirely as well  so that there is no need.  It becomes proactive kind of like information, presentation,  served up, yeah.  Yeah, it seems entirely intuitive to me that it could be inferred  from most of what you're already doing  and most of what you're already typing in.  I don't see why you need to go to a place, a special interface  and type something in in this very particular way  and embed or encode all of your thought process  into a few sentences and then hope that the magic thing  brings information back.  It seems like based on everything you're doing,  you can infer that already.  So if I kind of track with your vision of the future  there, Brian, is the idea that you have a context to where AI  that's basically saying, hey, I was listening into your meeting.  It sounds like you needed to do these three things.  Here's a first draft.  I've done that.  That should be done.  It's basically a context to where and all of a sudden  in the context of the conversation,  it no longer requires you to take initiative  but it takes initiative and then offers you a draft  or maybe even iterates the draft.  Is that the kind of future you're imagining?  100%.  Yeah.  I mean, like I've hacked together,  I use this little device limitless that records meetings  and already picks up the work to do.  And then to reblead a great little thing  that talked to my to do is kind of thing  so it just puts in there.  When that happens, you're like,  holy shit, this is just incredible.  Where do you think we are in that?  I mean, like you guys were in many ways,  as I understand it before the perplexity  and the Googles of the world too.  And I realized you business have evolved  since my favorite Chrome plug-in extension.  But you were quick to see that that's where the world would have.  Where are you and how quickly we will move  to what you're suggesting?  I think it'll happen fairly quickly.  I actually don't think that we need any new hardware.  I'm not on the new hardware boat.  Seems like we have everything we need.  There are already plenty of devices around us  that you're thinking like you don't need like  a little device to have a laptop.  You already have a phone.  Like everything's already happening there.  Anyways, I don't see why you need a specific piece of hardware  sitting on a table.  How do you think about, I agree with you  that they're listing devices everywhere.  There's something interesting about trust  where right now I have to have the wherewithal  to open a notion transcriber, for example,  or buy a limit list or something like that.  I'm always, by way of analogy,  I'm always somewhat skeptical whenever I see the pop-up  come up that says, turn on location services.  I'm like, why do they need to know where I am, you know?  And so, and often I find myself not doing that.  To your point about hardware is already here.  It does require kind of a level of trust  and a level of opt-in that basically I'm comfortable  being listened to all the time effectively.  And I agree that if that's true,  then we have all the hardware we need.  I wonder how much of a hurdle or how much friction it is  to basically, I think, I'd create me if I'm wrong,  but I think basically what we need is for humans  who've got these devices to basically say,  sure, listen to everything, right?  Is that what we need?  Why would you trust a new hardware device  more than the ones in your pocket?  Only because the phone factor kind of like  has a different use of behavior  and understanding of trust, right?  Because I think what Jeremy gets to is I use  this example and other podcasts,  but like increasingly a lot of students now write  their job applications with AI.  So they make thousands and companies get thousands  so they read the with AI.  So the agent to agent workflow  that is now replacing the human to human workflow  basically makes the original workflow up to the right.  And one of the issues, I assume everybody puts  granola whatever on for every conversation.  So I would assume that if a conversation  that I have through whatever online medium is recorded,  but I'm not sure that the world has kind of really  catched up, but I'm not sure that the way that I talk  completely freely with Jeremy,  when I think I'm not really recorded,  it is not necessarily something that I would truly enjoy.  And so I do think that there is like an interesting use case  of we have this world that has the notion  of sometimes you're recorded and sometimes you're not,  sometimes you're documenting and sometimes you're not.  And now that we're documenting all the time,  we'll probably have a bunch of workflows or trust issues  that we'll have to kind of figure out.  Oh, I 100% agree with that.  Yeah, I think that that's true regardless  of whether it's a new device or not.  For sure, but absolutely this issue of trust  seems like perhaps the opportunity  for some sort of technical innovation  that would bridge that trust gap  maybe even more so than AI at this point.  Right, like maybe innovating on some sort of model  where people could trust because I don't know  that that is there.  I don't know that I personally have seen a model  that I truly trust enough.  I wonder if there's almost like a,  I'm just kind of entering the role  of product design with you here for a moment.  I'm wondering if there's almost something like,  give us a day, turn this on.  And by the way, the default setting  is it turns off after a day.  But give us one day and see what we do for you.  And then to you, I think the design challenges  what can you proactively serve up  that goes so far, you know, I mean,  I gave the example I was interviewed  for a magazine recently and I had to wear  with all to think about taking that transcript,  put it into my clawed chief of staff  and get brutally on a feedback.  And that's actually super interesting,  gave me a bunch of stuff that I can work on  which I'm going to implement  for a meeting interview later today, right?  So that's helpful to me,  but it took me having to wear with all to realize,  wow, I have a communications expert available to me.  I wonder if there's like three or four things  like that where you know proactively  we're going to listen to the meeting  and we're going to tell them  what are three things you could do  to be a better teammate in your next meeting  and you block it on the calendar  and you look in the email  and you offer the help text for the next meeting, right?  Or whatever it is, right?  But it's got to be to me so tangible  and so discreet that if somebody turns it on  for merely 24 hours,  they go, I am never turning this thing off.  I think you're 100%, right?  I was thinking about this this weekend,  the same thing and I try to take it a little bit further  and just say, okay, give me one screenshot.  Like just what's the minimal amount of information  and the maximum, like maximum amount  of impact I can have  so that you want to turn it on again.  So that you want to give me a screenshot next hour  so that, oh, now if you increase the frequency  of the screenshots,  eventually it turns into like a recording of an hour  or whatever it is, but like,  how do I do this in such a way  that from screenshot one,  I'm providing immediately so much value  that you don't want to turn it off.  And I think if you can crack that  trust maybe comes secondary in people's minds.  We had Ilya on the podcast a few weeks back  who was one of the co-authors of the attention  that's all you need, paper.  And he's working on this kind of the blockchain  hybrid of AI,  where basically he feels that a lot of the trust will work  if suddenly people can own the information  itself at full access to the models,  but they don't necessarily pass on what happened.  And so I think that's kind of one area  that is at least interesting.  I'll babble a little because I think I talked to Dan Schieber  who's at every is local New York.  He had an interesting observation the other day  where he said that this trust's gonna come  because that where social media was about  just showing the most perfect version of ourselves,  which then led to everybody clicking on ambulances.  AI is interesting because it has this ability  of being insanely introspective, right?  Like suddenly you can literally listen to everything  and say, and they don't understand you much better.  And so he's coming to this thinking from yes,  trust will kind of get overcome  because there's gonna be like this ability  to show each yourself.  I know that you've written, you know,  these like met a subtle hints on the attention economy  and how other business models kind of fuel  a specific behavior of curious in terms of like  adding business model to all this.  What do you think you'll go and what are maybe you guys  trying to do to avoid the issues that you've written about?  Well, with U.com, we first and foremost  stayed away from the ads business.  I think that was, you know, the most successful business model  we've seen with Google, of course,  but one of the things that I didn't like  as much about the attention economy  when I was starting U.com.  So we've seen the world move more towards subscriptions,  which was like a major hurdle to get over on the AI side  because finally, no one is willing to pay for search.  But people are willing to pay for these AI summaries  which call out to search engines and summarize them for you.  So there was enough of a shift,  enough of a value increase for people  to start paying for it directly.  That enabled a lot.  And the fact that people are even willing to pay higher,  higher amounts for deeper and deeper workflows  and more and more automation is a great trend  for this type of thing.  So I think if you were ever to,  you know, enter this world of proactive search  that we were talking about as well before,  I would not want to give you all my data  if I had any inkling that it would just be used  to target me better, right?  So we might even need,  it might be a timing question  in that we need a little bit of space and time  from the world of super hyper optimized targeting  so that you do have the ability to trust anyone  or that type of data.  With U.com, we're an enterprise now.  You know, we don't,  there's your data retention policies.  You can do a multi-tenant setup.  You can bring your own key and encrypt it all.  We don't have that issue,  but we're not necessarily collecting everything  that you're doing all day, every day from your devices.  That would be like a next level set of data  that you'd really want to have some protections around.  It starts to feel like there's a,  you have to redefine targeting in some way, right?  When you think about proactivity,  it strikes me that sometimes what someone needs  is a thing or a recommendation or, right?  And then that's targeting isn't maybe motivated  by the other side of the ad marketplace.  But it is, you know, it is,  you could say altruistic.  It is benevolently intended.  Let's see, you start to think about,  how do we redefine targeting  where maybe we're just a one-sided,  there's not a marketplace.  We're only, you know what I mean?  It's an interesting kind of.  A hundred percent of the softening question.  The only reason I was thinking about  any of this constant context collection  and everything was, I don't know what I was trying to think  about how you could actually realize a lot  of the promises of social media and social networks  in connection.",
        "summary": "My main measure of productivity that I learned very early on was  my goal is to make the machines work for me as much as...",
        "keywords": [
            "My",
            "main",
            "measure",
            "of",
            "productivity"
        ],
        "sentiment": "Positive"
    }
]